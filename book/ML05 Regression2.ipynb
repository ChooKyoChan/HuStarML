{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning For Everyone\n",
    "Lecture notes for HuStar Project by idebtor@gmail.com \n",
    "**************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제 5 강: 선형 회귀 2 $^{Linear Regression}$ \n",
    "\n",
    "\n",
    "## 학습 목표\n",
    "    - 선형 회귀를 활용하여 기계 학습의 Workflow를 이해한다. \n",
    "    \n",
    "## 학습 내용\n",
    "    - 단순 선형 회귀(simple linear regression)\n",
    "    - 다중 선형 회귀(multiple linear regression)\n",
    "    - Training set vs Test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lesson is based on [A beginner’s guide to Linear Regression in Python with Scikit-Learn](https://towardsdatascience.com/a-beginners-guide-to-linear-regression-in-python-with-scikit-learn-83a8f7ae2b4f)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of supervised machine learning algorithms: \n",
    "    - Regression\n",
    "    - Classification\n",
    "\n",
    "The regression predicts continuous value outputs while the latter predicts discrete outputs. For instance, predicting the price of a house in dollars is a regression problem whereas predicting whether a tumor is malignant or benign is a classification problem.\n",
    "\n",
    "In this session, we will briefly study what linear regression is and how it can be implemented for both two variables and multiple variables using Scikit-Learn, which is one of the most popular machine learning libraries for Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단순 선형 회귀: Simple Linear Regression \n",
    "\n",
    "The term “linearity” in algebra refers to a linear relationship between two or more variables. If we draw this relationship in a two-dimensional space (between two variables), we get a straight line.\n",
    "\n",
    "Linear regression performs the task to predict a dependent variable value ($y$) based on a given independent variable ($x$). So, this regression technique finds out a linear relationship between $x$ (input) and $y$(output). Hence, the name is Linear Regression. If we plot the independent variable ($x$) on the x-axis and dependent variable ($y$) on the y-axis, linear regression gives us a straight line that best fits the data points, as shown in the figure below.\n",
    "\n",
    "We know that the equation of a straight line is basically: \n",
    "\n",
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/linear_reg1.png?raw=true\" width=\"400\">\n",
    "<center>그림 1: 선형 회귀 모델 </center> \n",
    "\n",
    "[source](https://pythonprogramming.net/regression-introduction-machine-learning-tutorial/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equation of the above line is : $y = wx + b$\n",
    "\n",
    "> Where $b$ is the bias (or intercept) and $w$ is the slope of the line. So basically, the linear regression algorithm gives us the most optimal value for the intercept and the slope (in two dimensions). The y and x variables remain the same, since they are the data features and cannot be changed. The values that we can control are the bias(b) and slope(w). There can be multiple straight lines depending upon the values of intercept and slope. Basically what the linear regression algorithm does is it fits multiple lines on the data points and returns the line that results in the least error.\n",
    "\n",
    "This same concept can be extended to cases where there are more than two variables. This is called multiple linear regression. For instance, consider a scenario where you have to predict the price of the house based upon its area, number of bedrooms, the average income of the people in the area, the age of the house, and so on. In this case, the dependent variable(target variable) is dependent upon several independent variables. A regression model involving multiple variables can be represented as:\n",
    "\n",
    "\\begin{align}\n",
    "y = w_0x_0 + w_1x_1 + w_2x_2 + w_3x_3 + … … w_mx_m, \\quad \\text{where} \\ x_0 = 1, \\text{and} \\ w_0 = b\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the equation of a __hyperplane__. Remember, a linear regression model in two dimensions is a straight line; in three dimensions it is a plane, and in more than three dimensions, a __hyperplane__.\n",
    "\n",
    "In this session, we will see how Python’s Scikit-Learn library for machine learning can be used to implement regression functions. We will start with simple linear regression involving two variables and then we will move towards linear regression involving multiple variables.\n",
    "\n",
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/linear_reg2.gif?raw=true\" width=\"400\">\n",
    "<center>그림 2: 선형 회귀 </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While exploring the Aerial Bombing Operations of World War Two dataset and recalling that the D-Day landings were nearly postponed due to poor weather, these weather reports may be downloaded from the period to compare with missions in the bombing operations dataset. \n",
    "\n",
    "You can download the dataset from [here](https://drive.google.com/open?id=1fiHg5DyvQeRC4SyhsVnje5dhJNyVWpO1).\n",
    "\n",
    "The dataset contains information on weather conditions recorded on each day at various weather stations around the world. Information includes precipitation, snowfall, temperatures, wind speed and whether the day included thunderstorms or other poor weather conditions.\n",
    "\n",
    "So our task is to predict the maximum temperature taking input feature as the minimum temperature.\n",
    "\n",
    "Let's start coding :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the required libraries :\n",
    "    \n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as seabornInstance \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command imports the CSV dataset using pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (7,8,18,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('./data/Weather.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s explore the data a little bit by checking the number of rows and columns in our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119040, 31)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You should receive output as $(119040, 31)$, which means the data contains $119040$ rows and $31$ columns.\n",
    "To see the statistical details of the dataset, we can use `describe()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STA</th>\n",
       "      <th>WindGustSpd</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MeanTemp</th>\n",
       "      <th>YR</th>\n",
       "      <th>MO</th>\n",
       "      <th>DA</th>\n",
       "      <th>DR</th>\n",
       "      <th>SPD</th>\n",
       "      <th>...</th>\n",
       "      <th>FT</th>\n",
       "      <th>FB</th>\n",
       "      <th>FTI</th>\n",
       "      <th>ITH</th>\n",
       "      <th>PGT</th>\n",
       "      <th>SD3</th>\n",
       "      <th>RHX</th>\n",
       "      <th>RHN</th>\n",
       "      <th>RVG</th>\n",
       "      <th>WTE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>119040.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>533.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>525.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29659.435795</td>\n",
       "      <td>37.774534</td>\n",
       "      <td>27.045111</td>\n",
       "      <td>17.789511</td>\n",
       "      <td>22.411631</td>\n",
       "      <td>43.805284</td>\n",
       "      <td>6.726016</td>\n",
       "      <td>15.797530</td>\n",
       "      <td>26.998124</td>\n",
       "      <td>20.396617</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.085333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20953.209402</td>\n",
       "      <td>10.297808</td>\n",
       "      <td>8.717817</td>\n",
       "      <td>8.334572</td>\n",
       "      <td>8.297982</td>\n",
       "      <td>1.136718</td>\n",
       "      <td>3.425561</td>\n",
       "      <td>8.794541</td>\n",
       "      <td>15.221732</td>\n",
       "      <td>5.560371</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.731328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10001.000000</td>\n",
       "      <td>18.520000</td>\n",
       "      <td>-33.333333</td>\n",
       "      <td>-38.333333</td>\n",
       "      <td>-35.555556</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11801.000000</td>\n",
       "      <td>29.632000</td>\n",
       "      <td>25.555556</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>20.555556</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22508.000000</td>\n",
       "      <td>37.040000</td>\n",
       "      <td>29.444444</td>\n",
       "      <td>21.111111</td>\n",
       "      <td>25.555556</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>33501.000000</td>\n",
       "      <td>43.059000</td>\n",
       "      <td>31.666667</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>27.222222</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>23.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>82506.000000</td>\n",
       "      <td>75.932000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>34.444444</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 STA  WindGustSpd        MaxTemp        MinTemp  \\\n",
       "count  119040.000000   532.000000  119040.000000  119040.000000   \n",
       "mean    29659.435795    37.774534      27.045111      17.789511   \n",
       "std     20953.209402    10.297808       8.717817       8.334572   \n",
       "min     10001.000000    18.520000     -33.333333     -38.333333   \n",
       "25%     11801.000000    29.632000      25.555556      15.000000   \n",
       "50%     22508.000000    37.040000      29.444444      21.111111   \n",
       "75%     33501.000000    43.059000      31.666667      23.333333   \n",
       "max     82506.000000    75.932000      50.000000      34.444444   \n",
       "\n",
       "            MeanTemp             YR             MO             DA          DR  \\\n",
       "count  119040.000000  119040.000000  119040.000000  119040.000000  533.000000   \n",
       "mean       22.411631      43.805284       6.726016      15.797530   26.998124   \n",
       "std         8.297982       1.136718       3.425561       8.794541   15.221732   \n",
       "min       -35.555556      40.000000       1.000000       1.000000    2.000000   \n",
       "25%        20.555556      43.000000       4.000000       8.000000   11.000000   \n",
       "50%        25.555556      44.000000       7.000000      16.000000   32.000000   \n",
       "75%        27.222222      45.000000      10.000000      23.000000   34.000000   \n",
       "max        40.000000      45.000000      12.000000      31.000000   78.000000   \n",
       "\n",
       "              SPD ...    FT   FB  FTI  ITH         PGT  SD3  RHX  RHN  RVG  \\\n",
       "count  532.000000 ...   0.0  0.0  0.0  0.0  525.000000  0.0  0.0  0.0  0.0   \n",
       "mean    20.396617 ...   NaN  NaN  NaN  NaN   12.085333  NaN  NaN  NaN  NaN   \n",
       "std      5.560371 ...   NaN  NaN  NaN  NaN    5.731328  NaN  NaN  NaN  NaN   \n",
       "min     10.000000 ...   NaN  NaN  NaN  NaN    0.000000  NaN  NaN  NaN  NaN   \n",
       "25%     16.000000 ...   NaN  NaN  NaN  NaN    8.500000  NaN  NaN  NaN  NaN   \n",
       "50%     20.000000 ...   NaN  NaN  NaN  NaN   11.600000  NaN  NaN  NaN  NaN   \n",
       "75%     23.250000 ...   NaN  NaN  NaN  NaN   15.000000  NaN  NaN  NaN  NaN   \n",
       "max     41.000000 ...   NaN  NaN  NaN  NaN   23.900000  NaN  NaN  NaN  NaN   \n",
       "\n",
       "       WTE  \n",
       "count  0.0  \n",
       "mean   NaN  \n",
       "std    NaN  \n",
       "min    NaN  \n",
       "25%    NaN  \n",
       "50%    NaN  \n",
       "75%    NaN  \n",
       "max    NaN  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, let’s plot our data points on a 2-D graph to eyeball our dataset and see if we can manually find any relationship between the data using the below script :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.plot(x='MinTemp', y='MaxTemp', style='.')  \n",
    "plt.title('MinTemp vs MaxTemp')  \n",
    "plt.xlabel('MinTemp')  \n",
    "plt.ylabel('MaxTemp')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s check the average max temperature and once we plot it we can observe that the Average Maximum Temperature is Between Nearly 25 and 35.As it can be seen, the line we have here is not that bad, since only a few points lie very far from it, most of the points lie around the line itself.\n",
    "\n",
    "- Visualizing the Test set results\n",
    "\n",
    "We do this using the following code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0576cb79e8e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Average maximum temperature which is between 25 and 35\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mseabornInstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'MaxTemp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.tight_layout()\n",
    "plt.title(\"Average maximum temperature which is between 25 and 35\")\n",
    "seabornInstance.distplot(dataset['MaxTemp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step is to divide the data into __attributes__ and __labels__.\n",
    "Attributes are the independent variables while labels are dependent variables whose values are to be predicted. In our dataset, we only have two columns. We want to predict the `MaxTemp` depending upon the `MinTemp` recorded. Therefore our attribute set will consist of the `MinTemp` column which is stored in the $X$ variable, and the label will be the `MaxTemp` column which is stored in $y$ variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset['MinTemp'].values.reshape(-1,1)\n",
    "y = dataset['MaxTemp'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split __80%__ of the data to the training set while __20%__ of the data to test set using below code.\n",
    "\n",
    "The `test_size` variable is where we actually specify the proportion of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After splitting the data into training and testing sets, finally, the time is to train our algorithm. For that, we need to import `LinearRegression` class, instantiate it, and call the `fit()` method along with our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()  \n",
    "regressor.fit(X_train, y_train) #training the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have discussed that the linear regression model basically finds the best value for the intercept and slope, which results in a line that best fits the data. To see the value of the intercept and slope calculated by the linear regression algorithm for our dataset, execute the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To retrieve the intercept:\n",
    "print(regressor.intercept_)\n",
    "#For retrieving the slope:\n",
    "print(regressor.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result should be approximately `10.66185201` and `0.92033997` respectively.\n",
    "\n",
    "This means that for every one unit of change in Min temperature, the change in the Max temperature is about 0.92%.\n",
    "\n",
    "Now that we have trained our algorithm, it’s time to make some predictions. To do so, we will use our test data and see how accurately our algorithm predicts the percentage score. To make predictions on the test data, execute the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compare the actual output values for `X_test` with the predicted values, execute the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison of Actual and Predicted value\n",
    "df = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': y_pred.flatten()})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize comparison result as a bar graph using the below script :\n",
    "\n",
    "Note: As the number of records is huge, for representation purpose we are taking just 25 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.head(25)\n",
    "df1.plot(kind='bar',figsize=(16,10))\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though our model is not very precise, the predicted percentages are close to the actual ones.\n",
    "\n",
    "Let's plot our straight line with the test data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction vs test data\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "plt.scatter(X_test, y_test,  color='gray', s = 2)\n",
    "plt.plot(X_test, y_pred, color='red', linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The straight line in the above graph shows our algorithm is correct.\n",
    "\n",
    "The final step is to evaluate the performance of the algorithm. This step is particularly important to compare how well different algorithms perform on a particular dataset. For regression algorithms, three evaluation metrics are commonly used:\n",
    "\n",
    "1. Mean Absolute Error (MAE) is the mean of the absolute value of the errors. It is calculated as:\n",
    "\\begin{align}\n",
    "\\mathbf{MAE} = \\frac{1}{n} \\sum_{j=1}^{n}|y_j - \\hat{y}_j|\n",
    "\\end{align}\n",
    "\n",
    "2. Mean Squared Error (MSE) is the mean of the squared errors and is calculated as:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{MSE} = \\frac{1}{N} \\sum_{j=1}^{n}(y_j - \\hat{y}_j)^2\n",
    "\\end{align}\n",
    "3. Root Mean Squared Error (RMSE) is the square root of the mean of the squared errors:\n",
    "\\begin{align}\n",
    "\\mathbf{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{j=1}^{n}(y_j - \\hat{y}_j)^2}\n",
    "\\end{align}\n",
    "\n",
    "Luckily, we don’t have to perform these calculations manually. The Scikit-Learn library comes with pre-built functions that can be used to find out these values for us.\n",
    "\n",
    "Let’s find the values for these metrics using our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should receive output like this (but probably slightly different):\n",
    "\n",
    "```\n",
    "('Mean Absolute Error:', 3.19932917837853)\n",
    "('Mean Squared Error:', 17.631568097568447)\n",
    "('Root Mean Squared Error:', 4.198996082109204)\n",
    "```\n",
    "\n",
    "You can see that the value of root mean squared error is $4.19$, which is more than 10% of the mean value of the percentages of all the temperature i.e. $22.41$. This means that our algorithm was not very accurate but can still make reasonably good prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some thoughts:\n",
    "In this session, it uses about 120,000 data samples. \n",
    "- Do you think we have the data enough or too many? \n",
    "- Determine whether or not we can reduce the total number of data used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다중 선형 회귀: Multiple Linear Regression \n",
    "\n",
    "A good introductory explanation is available from [here](https://hackernoon.com/an-intuitive-perspective-to-linear-regression-7dc566b2c14c)\n",
    "\n",
    "We just performed linear regression in the above section involving two variables. Almost all the real-world problems that you are going to encounter will have more than two variables. __Linear regression involving multiple variables is called “multiple linear regression” or multivariate linear regression__. The steps to perform multiple linear regression are almost similar to that of simple linear regression. The difference lies in the evaluation. You can use it to find out which factor has the highest impact on the predicted output and how different variables relate to each other.\n",
    "\n",
    "A red wine quality dataset related to red variants of the Portuguese “Vinho Verde” wine is used in this session. Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take into account various input features like fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates, alcohol. Based on these features we will predict the quality of the wine.\n",
    "\n",
    "Now, let's start our coding :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the required libraries :\n",
    "\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as seabornInstance \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command imports the dataset from the file you downloaded via the link above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/winequality.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s explore the data a little bit by checking the number of rows and columns in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will give $(1599, 12)$ as output which means our dataset has $1599$ rows and $12$ columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the statistical details of the dataset, we can use describe():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us clean our data little bit, So first check which are the columns the contains NaN values in it :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the above code is executed, all the columns should give False, In case for any column you find True result, then remove all the null values from that column using below code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step is to divide the data into __attributes__ and __labels__. The variable $\\mathbf{X}$ contains all the __attributes/features__ and $\\mathbf{y}$ variable contains __labels__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates','alcohol']].values\n",
    "y = dataset['quality'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the average value of the “quality” column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.tight_layout()\n",
    "plt.title(\"Average value of the quality of the wine\")\n",
    "seabornInstance.distplot(dataset['quality'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe that most of the time the value is either 5 or 6.\n",
    "\n",
    "Next, we split 80% of the data to the training set while 20% of the data to test set using below code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()  \n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As said earlier, in the case of multivariable linear regression, the regression model has to find the most optimal coefficients for all the attributes. To see what coefficients our regression model has chosen, execute the following script:\n",
    "\n",
    "__A sample run:__\n",
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/linear_reg3.png?raw=true\" width=\"250\">\n",
    "<center>그림 3: 다중 회귀 모델이 선택한 최적인 계수들 </center> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Debugging:\n",
    "The [original code](https://towardsdatascience.com/a-beginners-guide-to-linear-regression-in-python-with-scikit-learn-83a8f7ae2b4f) has a bug in the following.  Why don't debug it?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df = pd.DataFrame(regressor.coef_, X.columns, columns=['Coefficient'])  \n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This means that for a unit increase in “density”, there is a decrease of 31.51 units in the quality of the wine. Similarly, a unit decrease in “Chlorides“ results in an increase of 1.87 units in the quality of the wine. We can see that the rest of the features have very little effect on the quality of the wine.\n",
    "\n",
    "Now let's do prediction on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the difference between the actual value and predicted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison between Actual and Predicted value\n",
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "df1 = df.head(25)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the comparison of Actual and Predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.plot(kind='bar',figsize=(10,8))\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.title(\"Bar graph showing the difference between Actual and predicted value\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe here that our model has returned pretty good prediction results.\n",
    "The final step is to evaluate the performance of the algorithm. We’ll do this by finding the values for MAE, MSE, and RMSE. Execute the following script:\n",
    "\n",
    "A sample run:\n",
    "```\n",
    "('Mean Absolute Error:', 0.46963309286611077)\n",
    "('Mean Squared Error:', 0.38447119782012446)\n",
    "('Root Mean Squared Error:', 0.6200574149384268)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the value of root mean squared error is 0.62, which is slightly greater than 10% of the mean value which is 5.63. This means that our algorithm was __not very accurate__ but can still make __reasonably good__ predictions.\n",
    "\n",
    "There are many factors that may have contributed to this inaccuracy, for example :\n",
    "\n",
    "- __Need more data:__ We need to have a huge amount of data to get the best possible prediction.\n",
    "- __Bad assumptions:__ We made the assumption that this data has a linear relationship, but that might not be the case. Visualizing the data may help you determine that.\n",
    "- __Poor features:__ The features we used may not have had a high enough correlation to the values we were trying to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We studied the most fundamental machine learning algorithms i.e. linear regression. We implemented both simple linear regression and multiple linear regression with the help of the Scikit-Learn machine learning library.\n",
    "\n",
    "Most of this contents are from [KDnuggets article](https://www.kdnuggets.com/2019/03/beginners-guide-linear-regression-python-scikit-learn.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "_Rejoice always, pray continually, give thanks in all circumstances; for this is God’s will for you in Christ Jesus. (1 Thes 5:16-18)_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
