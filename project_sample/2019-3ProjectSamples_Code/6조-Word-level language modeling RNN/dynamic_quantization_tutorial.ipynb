{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word-level language modeling RNN\n",
    "==================================================================\n",
    "\n",
    "\n",
    "## 선정이유\n",
    ": 문장을 새로 만든다는게 신기해서 한번 해보고 싶었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 소개\n",
    "------------\n",
    "This example trains a multi-layer RNN (Elman, GRU, or LSTM) on a language modeling task. By default, the training script uses the Wikitext-2 dataset, provided. The trained model can then be used by the generate script to generate new text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요\n",
    "-----------\n",
    "pytorch 1.3이상"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. 필요한 라이브러리를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from io import open\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn     # torch neural network 패키지를 가져옵니다.\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 모델을 정의합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout: https://laonple.blog.me/220542170499\n",
    "Embedding: https://blog.naver.com/limitsinx/221598890687"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhid, nlayers, dropout=0.5):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.drop = nn.Dropout(dropout)  # 랜덤하게 노드를 무시하여 오버피팅을 피하는 효과를 갖습니다. 또한 특정 노드의 가중치가\n",
    "                                         # 너무 큰 영향을 주는 상황을 방지하게 해줍니다.\n",
    "        self.encoder = nn.Embedding(ntoken, ninp) # 단어를 저차원(2~3) 실수 벡터로 표현합니다. 기존에 one-hot encoding은 모든 단어를 1또는 0\n",
    "                                                  # 으로 이루어진 벡터로 표현해서 단어의 수가 늘수록 벡터의 차원이 커지는 단점이 있어\n",
    "                                                  # 이를 개선한 방법입니다. 또한 단어간 거리를 측정 가능하여 단어간 유사도를 알 수 있습니다.\n",
    "        self.rnn = nn.LSTM(ninp, nhid, nlayers, dropout=dropout) \n",
    "        self.decoder = nn.Linear(nhid, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "        self.nhid = nhid\n",
    "        self.nlayers = nlayers\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        emb = self.drop(self.encoder(input))\n",
    "        output, hidden = self.rnn(emb, hidden)\n",
    "        output = self.drop(output)\n",
    "        decoded = self.decoder(output)\n",
    "        return decoded, hidden\n",
    "\n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters())\n",
    "        return (weight.new_zeros(self.nlayers, bsz, self.nhid),\n",
    "                weight.new_zeros(self.nlayers, bsz, self.nhid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 텍스트 데이터를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Dictionary in module __main__ object:\n",
      "\n",
      "class Dictionary(builtins.object)\n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  add_word(self, word)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Dictionary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dictionary(object):\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = []\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2idx:\n",
    "            self.idx2word.append(word)\n",
    "            self.word2idx[word] = len(self.idx2word) - 1\n",
    "        return self.word2idx[word]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx2word)\n",
    "\n",
    "\n",
    "class Corpus(object):\n",
    "    def __init__(self, path):\n",
    "        self.dictionary = Dictionary()\n",
    "        self.train = self.tokenize(os.path.join(path, 'train.txt'))\n",
    "        self.valid = self.tokenize(os.path.join(path, 'valid.txt'))\n",
    "        self.test = self.tokenize(os.path.join(path, 'test.txt'))    #각 멤버에 텍스트 데이터를 초기화시킵니다.\n",
    "\n",
    "    def tokenize(self, path):\n",
    "        \"\"\"Tokenizes a text file.\"\"\"\n",
    "        assert os.path.exists(path)\n",
    "        # Add words to the dictionary\n",
    "        with open(path, 'r', encoding=\"utf8\") as f:\n",
    "            for line in f:\n",
    "                words = line.split() + ['<eos>']\n",
    "                for word in words:\n",
    "                    self.dictionary.add_word(word)\n",
    "\n",
    "        # Tokenize file content\n",
    "        with open(path, 'r', encoding=\"utf8\") as f:\n",
    "            idss = []\n",
    "            for line in f:\n",
    "                words = line.split() + ['<eos>']\n",
    "                ids = []\n",
    "                for word in words:\n",
    "                    ids.append(self.dictionary.word2idx[word])\n",
    "                idss.append(torch.tensor(ids).type(torch.int64))\n",
    "            ids = torch.cat(idss)\n",
    "\n",
    "        return ids\n",
    "\n",
    "model_data_filepath = 'data/'\n",
    "\n",
    "corpus = Corpus(model_data_filepath + 'wikitext-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   2-2. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --epochs 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 학습된 모델을 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMModel(\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (encoder): Embedding(33278, 512)\n",
      "  (rnn): LSTM(512, 256, num_layers=5, dropout=0.5)\n",
      "  (decoder): Linear(in_features=256, out_features=33278, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ntokens = len(corpus.dictionary)\n",
    "\n",
    "model = LSTMModel(\n",
    "    ntoken = ntokens,\n",
    "    ninp = 512,\n",
    "    nhid = 256,\n",
    "    nlayers = 5,\n",
    ")\n",
    "\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        model_data_filepath + 'word_language_model_quantize.pth',\n",
    "        map_location=torch.device('cpu')\n",
    "        )\n",
    "    )\n",
    "\n",
    "model.eval()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Generated 0/1000 words\n",
      "| Generated 100/1000 words\n",
      "| Generated 200/1000 words\n",
      "| Generated 300/1000 words\n",
      "| Generated 400/1000 words\n",
      "| Generated 500/1000 words\n",
      "| Generated 600/1000 words\n",
      "| Generated 700/1000 words\n",
      "| Generated 800/1000 words\n",
      "| Generated 900/1000 words\n",
      "b'<unk>' b'Intelligence' b'as' b'king' b'Wilhelm' b'<unk>' b'Leo' b'Richard' b',' b'leaves' b'at' b'its' b'Loutit' b'.' b'In' b'the' b'context' b'of' b'Mikhail' b'@-@'\n",
      "b'Admiral' b',' b'it' b'is' b'an' b'member' b'of' b'that' b'of' b'Omar' b\"'s\" b'supporters' b'Edith' b'role' b',' b'which' b'could' b'have' b'also' b'moved'\n",
      "b'longer' b'to' b'do' b'so' b'mouth' b'for' b'Swedish' b'scenes' b'.' b'Both' b'in' b'his' b'microscope' b'and' b'the' b'creation' b'of' b'other' b'detail' b','\n",
      "b'such' b'as' b'binary' b'droppings' b'on' b'the' b'map' b',' b'was' b'assigned' b'for' b'trees' b'.' b'It' b'does' b'not' b'sell' b'them' b'to' b'be'\n",
      "b'placed' b'back' b'to' b'<unk>' b'General' b'Armstrong' b'720' b'then' b'species' b',' b'and' b'the' b'backdrop' b'of' b'<unk>' b'birds' b'vary' b'from' b'times' b'.'\n",
      "b'Therefore' b',' b'they' b'were' b'sought' b'to' b'be' b'described' b'by' b'<unk>' b'as' b'<unk>' b'and' b'may' b'be' b'used' b'to' b'establish' b'to' b'the'\n",
      "b'further' b'@-@' b'subject' b'in' b'the' b'deaths' b'of' b'the' b'possibility' b'of' b'Cage' b'to' b'their' b'body' b'.' b'Although' b'they' b'may' b'be' b'inflicted'\n",
      "b'by' b'demand' b'<unk>' b',' b'Latin' b',' b'steeply' b',' b'to' b'produce' b',' b'feels' b'because' b'his' b'considers' b'model' b'might' b'move' b'to' b'all'\n",
      "b'other' b'research' b',' b'variety' b'of' b'<unk>' b':' b'Unlike' b'<unk>' b',' b'the' b'conditions' b'of' b'HNS' b'to' b'serve' b'it' b'high' b'to' b'gigantic'\n",
      "b',' b'bringing' b'cable' b'from' b'over' b'of' b'now' b'control' b'for' b'more' b'than' b'50' b'%' b'of' b'the' b'season' b'.' b'In' b'2013' b','\n",
      "b'not' b'so' b'hide' b'pardon' b'settles' b'in' b'Africaine' b',' b'multiple' b'years' b',' b'and' b'<unk>' b'.' b'Although' b'they' b'let' b'the' b'primary' b'were'\n",
      "b'discovered' b'into' b'the' b'Lewis' b',' b'education' b'in' b'2006' b',' b'the' b'<unk>' b'Phoenician' b'tide' b'are' b',' b'as' b'well' b'as' b'traditional' b'eagle'\n",
      "b',' b'Emperor' b'of' b'Poland' b'design' b'as' b'Frigate' b'Murray' b'praise' b'a' b'ice' b'egg' b'of' b'escape' b'.' b'The' b'ancient' b'weapon' b'severe' b'god'\n",
      "b'-' b'it' b'depend' b'.' b'In' b'particular' b',' b'it' b'will' b'be' b'necessary' b':' b'to' b'assist' b',' b'traits' b'of' b'goods' b'have' b'<unk>'\n",
      "b'screens' b',' b'so' b'thus' b'allowing' b'24' b'an' b'innovation' b'of' b'interest' b'dismounted' b',' b'scattered' b'as' b'they' b'will' b'be' b'distinguished' b'below' b'reducing'\n",
      "b'or' b'upsetting' b'them' b'to' b'write' b'.' b'<eos>' b'<eos>' b'=' b'=' b'Aftermath' b'=' b'=' b'<eos>' b'<eos>' b'Gerald' b'occurrences' b'near' b'Department' b'of'\n",
      "b'energy' b'was' b'celebrated' b'in' b'doses' b'on' b'his' b'study' b'when' b'along' b'.' b'His' b'plans' b'for' b'Ceres' b'are' b'that' b'bouncers' b',' b'in'\n",
      "b'1842' b',' b'could' b'be' b'introduced' b'for' b'odd' b'servants' b'near' b'areas' b'.' b'For' b'example' b',' b'the' b'common' b'birds' b'introduced' b'it' b'to'\n",
      "b'imaginative' b'patterns' b'.' b'The' b'splicing' b'Legends' b'had' b'long' b'differentiate' b'for' b'1' b'@.@' b'4' b'%' b'of' b'each' b'soldier' b',' b'and' b'u'\n",
      "b'causes' b'a' b'ensemble' b',' b'with' b'movement' b'feathers' b'every' b'plumage' b'of' b'sorts' b'.' b'<unk>' b'peers' b'may' b'give' b'a' b'break' b'and' b'they'\n",
      "b'lay' b'human' b'water' b',' b'and' b'it' b'does' b'a' b'Ad' b'jobs' b'by' b'250' b'pistols' b'per' b'square' b'females' b'.' b'They' b'<unk>' b'eggs'\n",
      "b'under' b'octagonal' b'movements' b'and' b'also' b'its' b'most' b'Majesty' b'may' b'be' b'shops' b'during' b'they' b'are' b'than' b'Ravidas' b',' b'a' b'number' b'of'\n",
      "b'additional' b',' b'<unk>' b',' b'falling' b'excess' b'showed' b'them' b'to' b'convert' b'good' b'or' b'anxiety' b'.' b'Also' b',' b'itself' b'<unk>' b'championships' b'and'\n",
      "b'falcon' b'rose' b'to' b'support' b'birds' b',' b'generally' b'for' b'.' b'This' b'can' b'stop' b'summons' b'so' b',' b'on' b'12' b'.' b'Once' b'their'\n",
      "b'time' b'is' b'fought' b'to' b'a' b'flat' b'brahmin' b'bird' b',' b'instead' b'may' b'be' b'threatened' b'.' b'<eos>' b'Noisy' b'Storm' b'Ferry' b'has' b'recommended'\n",
      "b'humans' b'on' b'response' b'.' b'Later' b',' b'Raven' b'occur' b'after' b'its' b'individual' b'grew' b'as' b'battle' b'.' b'Ceres' b'was' b'either' b'well' b'in'\n",
      "b',' b'but' b'one' b'of' b'their' b'60' b'meters' b'.' b'The' b'chicks' b',' b'by' b'John' b'612' b',' b'is' b'written' b',' b'where' b'common'\n",
      "b'rotation' b'can' b'be' b'further' b'present' b'.' b'These' b'243' b'metres' b'(' b'109' b'ft' b')' b'of' b'roads' b',' b'as' b'they' b'predict' b'heated'\n",
      "b'the' b'planet' b'in' b'any' b'planets' b'.' b'<eos>' b'The' b'kakapo' b'is' b'normally' b'evident' b'prior' b'to' b'most' b'19th' b'or' b'more' b'Agriculture' b'parrot'\n",
      "b',' b'when' b'other' b'still' b'significantly' b'of' b'them' b'Course' b'.' b'These' b'<unk>' b';' b'treating' b'during' b'many' b'hands' b'by' b'high' b'parrots' b','\n",
      "b'is' b'found' b'by' b'the' b'breeding' b'female' b'.' b'On' b'main' b'bow' b',' b'the' b'player' b'decided' b'the' b'nest' b'<unk>' b'that' b'may' b'be'\n",
      "b'discouraged' b'.' b'congregation' b'enter' b'ourselves' b'enzymes' b'in' b'regulation' b'or' b'reduced' b'clearance' b'.' b'These' b'association' b'with' b'not' b'intermediate' b'coteries' b'are' b'completely'\n",
      "b'entirely' b'fixed' b'.' b'Once' b'there' b'have' b'no' b'inconsistent' b',' b'hair' b'with' b'birds' b'consisting' b'of' b'chicks' b'relating' b'to' b'individual' b'red' b'or'\n",
      "b'contracting' b'clouds' b'.' b'Males' b'do' b'not' b'hope' b'around' b'4' b'miles' b'(' b'1' b'mi' b')' b'for' b'some' b'females' b'in' b'venues' b'.'\n",
      "b'Another' b'longest' b'may' b'be' b'smooth' b'so' b'by' b'even' b'serious' b',' b'and' b'attackers' b'or' b'grey' b'measures' b'tracks' b'may' b'be' b'distinguished' b'by'\n",
      "b'eye' b'white' b'and' b'ventral' b'cisterns' b'.' b'<eos>' b'food' b'(' b't1' b')' b'allows' b'much' b'large' b'eggs' b'from' b'islands' b'alignment' b'or' b'dams'\n",
      "b',' b'due' b'to' b'a' b'active' b'larger' b',' b'bit' b'@-@' b'like' b'broad' b'kingship' b'.' b'Nearly' b'some' b'characteristic' b'of' b'the' b'<unk>' b\"'s\"\n",
      "b'structure' b'to' b'weaken' b'birds' b',' b'often' b'needs' b'to' b'fuse' b'sperm' b'punishment' b'in' b'sunny' b',' b'small' b'activities' b')' b'makes' b'their' b'cellular'\n",
      "b'defined' b'of' b'hanging' b'to' b'speak' b'gum' b',' b'aziridines' b',' b'which' b'seek' b'to' b'be' b'close' b'to' b'the' b'submarine' b'.' b'Males' b'also'\n",
      "b'uses' b'young' b'eggs' b'for' b'patrolling' b'as' b'others' b'to' b'break' b'.' b'<eos>' b'There' b'are' b'no' b'species' b'in' b'height' b'and' b'sections' b'of'\n",
      "b'planets' b'on' b'common' b'areas' b'.' b'They' b'are' b'fight' b'during' b'this' b'phase' b',' b'without' b'broader' b'birds' b',' b'no' b'<unk>' b'folklore' b'.'\n",
      "b'Only' b'regions' b'may' b'bind' b'expensive' b'their' b'long' b'symptoms' b'.' b'<eos>' b'Because' b'their' b'artificial' b'print' b',' b'forcing' b'double' b'nuclei' b',' b'the'\n",
      "b'starling' b'may' b'be' b'distinguished' b'by' b'two' b'or' b'even' b'are' b'submerged' b'.' b'Females' b'are' b'commonly' b'crushed' b'through' b'a' b'nest' b'or' b'irrigation'\n",
      "b'it' b'with' b'holes' b'when' b'cannot' b'need' b'to' b'be' b'decreasing' b'in' b'both' b'human' b'areas' b',' b'and' b'may' b'be' b'killed' b'by' b'their'\n",
      "b'common' b'wives' b',' b'which' b'model' b'ungulates' b'support' b'across' b'his' b'<unk>' b'to' b'minimize' b'a' b'new' b'eye' b'.' b'This' b'move' b',' b'when'\n",
      "b'large' b'significance' b'are' b'introduced' b'for' b'for' b'the' b'bird' b'efforts' b'.' b'<eos>' b'<eos>' b'=' b'=' b'sulfur' b'type' b'=' b'=' b'<eos>' b'<eos>'\n",
      "b'Amanita' b'spots' b',' b'176' b'geometry' b',' b'and' b'<unk>' b',' b'regaining' b'ballet' b',' b'and' b'distantly' b'<unk>' b'.' b'This' b'is' b'consumed' b'by'\n",
      "b'at' b'least' b'most' b'resources' b'are' b'communal' b'by' b'equilibrium' b',' b'near' b'certain' b',' b'mainland' b'orbits' b'on' b'several' b'islands' b',' b'turned' b'to'\n",
      "b'date' b'since' b'they' b'temperature' b',' b'has' b'no' b'damage' b'.' b'Since' b'they' b'can' b'gather' b',' b'after' b'205' b'metres' b'(' b'254' b'km'\n",
      "b')' b',' b'measures' b'that' b'forms' b'their' b'wings' b'occur' b'in' b'the' b'other' b'ocean' b'death' b'and' b':' b'\"' b'Half' b'fever' b'games' b'are'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_ = torch.randint(ntokens, (1, 1), dtype=torch.long)\n",
    "hidden = model.init_hidden(1)\n",
    "temperature = 1.0\n",
    "num_words = 1000\n",
    "\n",
    "with open(model_data_filepath + 'out.txt', 'w') as outf:\n",
    "    with torch.no_grad():  # no tracking history\n",
    "        for i in range(num_words):\n",
    "            output, hidden = model(input_, hidden)\n",
    "            word_weights = output.squeeze().div(temperature).exp().cpu()\n",
    "            word_idx = torch.multinomial(word_weights, 1)[0]\n",
    "            input_.fill_(word_idx)\n",
    "\n",
    "            word = corpus.dictionary.idx2word[word_idx]\n",
    "\n",
    "            outf.write(str(word.encode('utf-8')) + ('\\n' if i % 20 == 19 else ' '))\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print('| Generated {}/{} words'.format(i, 1000))\n",
    "\n",
    "with open(model_data_filepath + 'out.txt', 'r') as outf:\n",
    "    all_output = outf.read()\n",
    "    print(all_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's no GPT-2, but it looks like the model has started to learn the structure of\n",
    "language!\n",
    "\n",
    "We're almost ready to demonstrate dynamic quantization. We just need to define a few more\n",
    "helper functions:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = 25\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "eval_batch_size = 1\n",
    "\n",
    "# create test data set\n",
    "def batchify(data, bsz):\n",
    "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    # Evenly divide the data across the bsz batches.\n",
    "    return data.view(bsz, -1).t().contiguous()\n",
    "\n",
    "test_data = batchify(corpus.test, eval_batch_size)\n",
    "\n",
    "# Evaluation functions\n",
    "def get_batch(source, i):\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].view(-1)\n",
    "    return data, target\n",
    "\n",
    "def repackage_hidden(h):\n",
    "  \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
    "\n",
    "  if isinstance(h, torch.Tensor):\n",
    "      return h.detach()\n",
    "  else:\n",
    "      return tuple(repackage_hidden(v) for v in h)\n",
    "\n",
    "def evaluate(model_, data_source):\n",
    "    # Turn on evaluation mode which disables dropout.\n",
    "    model_.eval()\n",
    "    total_loss = 0.\n",
    "    hidden = model_.init_hidden(eval_batch_size)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, data_source.size(0) - 1, bptt):\n",
    "            data, targets = get_batch(data_source, i)\n",
    "            output, hidden = model_(data, hidden)\n",
    "            hidden = repackage_hidden(hidden)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += len(data) * criterion(output_flat, targets).item()\n",
    "    return total_loss / (len(data_source) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Test dynamic quantization\n",
    "----------------------------\n",
    "\n",
    "Finally, we can call ``torch.quantization.quantize_dynamic`` on the model!\n",
    "Specifically,\n",
    "\n",
    "- We specify that we want the ``nn.LSTM`` and ``nn.Linear`` modules in our\n",
    "  model to be quantized\n",
    "- We specify that we want weights to be converted to ``int8`` values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Didn't find engine for operation quantized::linear_prepack NoQEngine (operator () at ..\\aten\\src\\ATen\\native\\quantized\\cpu\\qlinear_prepack.cpp:202)\n(no backtrace available)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-39ae94846a04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m quantized_model = torch.quantization.quantize_dynamic(\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqint8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquantized_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\quantization\\quantize.py\u001b[0m in \u001b[0;36mquantize_dynamic\u001b[1;34m(model, qconfig_spec, dtype, mapping, inplace)\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[0mpropagate_qconfig_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqconfig_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m     \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\quantization\\quantize.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(module, mapping, inplace)\u001b[0m\n\u001b[0;32m    292\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mSWAPPABLE_MODULES\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m             \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m         \u001b[0mreassign\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswap_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreassign\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\quantization\\quantize.py\u001b[0m in \u001b[0;36mswap_module\u001b[1;34m(mod, mapping)\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'qconfig'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqconfig\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mDeQuantStub\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m             \u001b[0mnew_mod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_float\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_mod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\quantized\\dynamic\\modules\\rnn.py\u001b[0m in \u001b[0;36mfrom_float\u001b[1;34m(cls, mod)\u001b[0m\n\u001b[0;32m    390\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfrom_float\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_float\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\quantized\\dynamic\\modules\\rnn.py\u001b[0m in \u001b[0;36mfrom_float\u001b[1;34m(cls, mod)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'LSTM'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             qRNNBase = LSTM(mod.input_size, mod.hidden_size, mod.num_layers,\n\u001b[1;32m--> 242\u001b[1;33m                             mod.bias, mod.batch_first, mod.dropout, mod.bidirectional, dtype)\n\u001b[0m\u001b[0;32m    243\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Only LSTM is supported for QuantizedRNN for now'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\quantized\\dynamic\\modules\\rnn.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'LSTM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\quantized\\dynamic\\modules\\rnn.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, mode, input_size, hidden_size, num_layers, bias, batch_first, dropout, bidirectional, dtype)\u001b[0m\n\u001b[0;32m    106\u001b[0m                 \u001b[0msuffix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'_reverse'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdirection\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m                 ih_params, ih_param_names = process_weights(\n\u001b[1;32m--> 108\u001b[1;33m                     'ih', layer, suffix, w_ih, b_ih, dtype)\n\u001b[0m\u001b[0;32m    109\u001b[0m                 hh_params, hh_param_names = process_weights(\n\u001b[0;32m    110\u001b[0m                     'hh', layer, suffix, w_hh, b_hh, dtype)\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\quantized\\dynamic\\modules\\rnn.py\u001b[0m in \u001b[0;36mprocess_weights\u001b[1;34m(ihhh, layer, suffix, qweight, bias, dtype)\u001b[0m\n\u001b[0;32m     64\u001b[0m                         \u001b[1;31m#   w_ih, w_hh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m                         \u001b[0mpacked_weight\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_prepack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpacked_weight\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Didn't find engine for operation quantized::linear_prepack NoQEngine (operator () at ..\\aten\\src\\ATen\\native\\quantized\\cpu\\qlinear_prepack.cpp:202)\n(no backtrace available)"
     ]
    }
   ],
   "source": [
    "import torch.quantization\n",
    "\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    model, {nn.LSTM, nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "print(quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model looks the same; how has this benefited us? First, we see a\n",
    "significant reduction in model size:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 113.941528\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'quantized_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-16dc98ea2654>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint_size_of_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mprint_size_of_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquantized_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'quantized_model' is not defined"
     ]
    }
   ],
   "source": [
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')\n",
    "\n",
    "print_size_of_model(model)\n",
    "print_size_of_model(quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we see faster inference time, with no difference in evaluation loss:\n",
    "\n",
    "Note: we number of threads to one for single threaded comparison, since quantized\n",
    "models run single threaded.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 5.167\n",
      "elapsed time (seconds): 481.9\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'quantized_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-96f4a79d8b07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mtime_model_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtime_model_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquantized_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'quantized_model' is not defined"
     ]
    }
   ],
   "source": [
    "torch.set_num_threads(1)\n",
    "\n",
    "def time_model_evaluation(model, test_data):\n",
    "    s = time.time()\n",
    "    loss = evaluate(model, test_data)\n",
    "    elapsed = time.time() - s\n",
    "    print('''loss: {0:.3f}\\nelapsed time (seconds): {1:.1f}'''.format(loss, elapsed))\n",
    "\n",
    "time_model_evaluation(model, test_data)\n",
    "time_model_evaluation(quantized_model, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this locally on a MacBook Pro, without quantization, inference takes about 200 seconds,\n",
    "and with quantization it takes just about 100 seconds.\n",
    "\n",
    "Conclusion\n",
    "----------\n",
    "\n",
    "Dynamic quantization can be an easy way to reduce model size while only\n",
    "having a limited effect on accuracy.\n",
    "\n",
    "Thanks for reading! As always, we welcome any feedback, so please create an issue\n",
    "`here <https://github.com/pytorch/pytorch/issues>`_ if you have any.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
